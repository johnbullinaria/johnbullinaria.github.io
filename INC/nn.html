<HTML><HEAD> <TITLE>Implementing a Neural Network in C</TITLE></HEAD><BODY BGCOLOR="#FFFFFF"><FONT SIZE=3 FACE="Arial,Helvetica,Univers,Zurich BT,sans-serif"><H2 ALIGN=CENTER><FONT COLOR="#D00000">John Bullinaria's Step by Step Guide to Implementing a Neural Network in C</FONT></H2><H4 ALIGN=CENTER>By <A HREF="../index.html">John A. Bullinaria</a> from the<A HREF="http://www.cs.bham.ac.uk/">School of Computer Science</A> of <A HREF="http://www.bham.ac.uk/">The University of Birmingham, UK</A>. </CENTER></H4><P>This document contains a step by step guide to implementing a simple neural network in C.  It is aimed mainly at students who wish to (or have been told to) incorporate a neural network learning component into a larger system they are building.  Obviously there are many types of neural network one could consider using - here I shall concentrate on one particularly common and useful type, namely a simple fully-connected feed-forward back-propagation network (multi layer perceptron),consisting of an input layer, one hidden layer and an output layer.<P>This type of network will be useful when we have a set of input vectors and a corresponding set of output vectors, and the aim is for the network to produce an appropriate output for each input it is given.  Of course, if we already have a complete noise-free set of input and output vectors, then a simple look-up table would suffice.  However, if we want the system to <i>generalize</i>, i.e. produce appropriate outputs for inputs that have never been seen before, then a neural network that has <i>learned</i> how to map between the known inputs and outputs (i.e. the training data set) will often do a pretty good job for new inputs as well, particularly if an appropriate <i>regularization</i> techniquehas been used.  <P> I shall assume that the reader is already familiar with C, and for more details about neural networks in general there are plenty of good text-books and web-sites available (e.g., see my<A HREF="../inc.html">Neural Computation web-site</A>).  So, let us begin...<P>A single neuron (i.e. processing unit) takes its total input <i>In</i> and computes an associated output activation <i>Out</i>.  A popular activation function is the sigmoid function<P><ul>Out = 1.0/(1.0 + exp(-In));<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Out = Sigmoid(In) */</FONT><BR></ul><P>though other functions are often used (e.g., linear or hyperbolic tangent).  This has the effect of squashing the infinite range of <i>In</i> into the range 0 to 1.  It also has the convenient property that its derivative takes the particularly simple form<P><ul>Sigmoid_Derivative = Sigmoid * (1.0 - Sigmoid) ;<BR></ul>which proves useful when implementing the learning algorithm.Usually the input <i>In</i> into a given neuron will be the weighted sum of activations feeding in from the outputs of a number of other neurons.  It is convenient to think of the activations flowing through layers of neurons.  So, if there are <i>NumInput</i> neurons in the input layer, the total activation flowing into a hidden layer neuron is just the sum <i>SumH</i> over all <i>Input[i]*Weight[i]</i>, where <i>Weight[i]</i> is the strength/weight of the connection between unit <i>i</i> in the input layerand our unit in the hidden layer. Each neuron will also have a bias, or resting state, that is added to the sum of inputs, and it is convenient to call this <i>Weight[0]</i>.  This acts as theneuron <i>threshold</i>.  We can then compute the hidden unit activation with<P><ul>SumH = Weight[0] ;<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* start with the hidden unit bias */</FONT><BR>for( i = 1 ; i &lt;= NumInput ; i++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* i loop over input units */</FONT><BR><ul>SumH += Input[i] * Weight[i] ;<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* add in weighted contribution from each input unit */</FONT></ul>}<BR>Hidden = 1.0/(1.0 + exp(-SumH)) ;<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;/* compute sigmoid to give activation */</FONT><BR></ul><P>Normally the hidden layer will have many units as well, so it is appropriate to write the weights between input unit <i>i</i> and hidden layer unit <i>j</i> as an array <i>WeightIH[i][j]</i>, in which we have added the label <i>IH</i> to avoid confusion with any other weights in the network.  Thus to get the activation of unit  <i>j</i> in the hidden layer we have<P><math><ul>SumH[j] = WeightIH[0][j] ;<BR>for( i = 1 ; i &lt;= NumInput ; i++ ) {<BR><ul>SumH[j] += Input[i] * WeightIH[i][j] ;<BR></ul>}<BR>Hidden[j] = 1.0/(1.0 + exp(-SumH[j])) ;<BR></ul></math>Remember that in C the array indices start from zero, not one, so we would declare our variables as<P><math><ul>double Input[NumInput+1] ;<BR>double SumH[NumHidden+1] ;<BR>double Hidden[NumHidden+1] ;<BR>double WeightIH[NumInput+1][NumHidden+1] ;<BR>etc. </ul></math>(or, more likely, declare pointers and use <i>calloc</i> or <i>malloc</i> to allocate the memory).  Naturally, we need another loop to get all the hidden unit activations<P><math><ul>for( j = 1 ; j &lt;= NumHidden ; j++ ) {<BR><ul>SumH[j] = WeightIH[0][j] ;<BR>    for( i = 1 ; i &lt;= NumInput ; i++ ) {<BR>    <ul>SumH[j] += Input[i] * WeightIH[i][j] ;<BR></ul>    }<BR>    Hidden[j] = 1.0/(1.0 + exp(-SumH[j])) ;<BR></ul>}</ul></math><P>One hidden layer is necessary and sufficient for most purposes, so our hidden layer activations will feed into the output layer in the same way as above.The code can start to become confusing at this point - keeping a separate index <i>i, j, k</i> for each layer helps, as does an intuitive notation for distinguishing between the different layers of weights <i>WeightIH</i> and <i>WeightHO</i>, the sums of activations feeding into each layer <i>SumH</i> and <i>SumO</i>, and the resultant activations at each layer <i>Hidden</i> and <i>Output</i>.  The code thus becomes<P><math><ul>for( j = 1 ; j &lt;= NumHidden ; j++ ) { <FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* j loop computes hidden unit activations */</FONT><BR><ul>SumH[j] = WeightIH[0][j] ;<BR>    for( i = 1 ; i &lt;= NumInput ; i++ ) {<BR>    <ul>SumH[j] += Input[i] * WeightIH[i][j] ;<BR></ul>    }<BR>    Hidden[j] = 1.0/(1.0 + exp(-SumH[j])) ;<BR></ul>}<BR>for( k = 1 ; k &lt;= NumOutput ; k++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* k loop computes output unit activations */</FONT><ul>SumO[k] = WeightHO[0][k] ;<BR>    for( j = 1 ; j &lt;= NumHidden ; j++ ) {<BR>    <ul>SumO[k] += Hidden[j] * WeightHO[j][k] ;<BR></ul>    }<BR>    Output[k] = 1.0/(1.0 + exp(-SumO[k])) ;<BR></ul>}</ul></math>and the network takes on the familiar form that we shall use for the remainder of this document<P><CENTER> <IMG  SRC="nn.gif"></CENTER><P>Generally we will have a whole set of <i>NumPattern</i> training patterns, i.e. pairs of input and target output vectors,<P><ul>{ Input[p][i] , Target[p][k] }</ul><P>labelled by the index <i>p</i>. The network learns by minimizing some measure of the error of the network's actual outputs compared with the target outputs.  For example, the sum squared error over all output units <i>k</i> and all training patterns <i>p</i> will be given by<P><math><ul>Error = 0.0 ;<BR>for( p = 1 ; p &lt;= NumPattern ; p++ ) {<BR><ul>for( k = 1 ; k &lt;= NumOutput ; k++ ) {<BR>    <ul>Error += 0.5 * (Target[p][k] - Output[p][k]) * (Target[p][k] - Output[p][k]) ;<BR></ul>    }<BR></ul>}</ul></math><P>(The factor of 0.5 is conventionally included to simplify the algebra in deriving the learning algorithm.) If we insert the above code for computing the network outputs into the <i>p</i> loop of this, we end up with<P><math><ul>Error = 0.0 ;<BR>for( p = 1 ; p &lt;= NumPattern ; p++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* p loop over training patterns */</FONT><BR><ul>for( j = 1 ; j &lt;= NumHidden ; j++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* j loop over hidden units */</FONT><BR><ul>SumH[p][j] = WeightIH[0][j] ;<BR>    for( i = 1 ; i &lt;= NumInput ; i++ ) {<BR>    <ul>SumH[p][j] += Input[p][i] * WeightIH[i][j] ;<BR></ul>    }<BR>    Hidden[p][j] = 1.0/(1.0 + exp(-SumH[p][j])) ;<BR></ul>}<BR>for( k = 1 ; k &lt;= NumOutput ; k++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* k loop over output units */</FONT><BR><ul>SumO[p][k] = WeightHO[0][k] ;<BR>    for( j = 1 ; j &lt;= NumHidden ; j++ ) {<BR>    <ul>SumO[p][k] += Hidden[p][j] * WeightHO[j][k] ;<BR></ul>    }<BR>    Output[p][k] = 1.0/(1.0 + exp(-SumO[p][k])) ;<BR>    Error += 0.5 * (Target[p][k] - Output[p][k]) * (Target[p][k] - Output[p][k]) ;<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;/* Sum Squared Error */</FONT><BR></ul>    }<BR></ul>}<BR></ul><P>I'll leave the reader to dispense with any indices that they don't need for the purposes of their own system (e.g., the indices on <i>SumH</i> and <i>SumO</i>).  <P>The next stage is to iteratively adjust the weights to minimize the network's error.  A standard way to do this is by performing 'gradient descent' on the error function.  We compute analytically how much the error is changed by a small change in each weight (i.e. compute the partial derivatives d<i>Error</i>/d<i>Weight</i>) and shift the weights by a small amount <i>DeltaWeight</i> in the direction that most reduces the error.  The literature is full of variations on this general approach - here we shall implemant the 'standard on-line back-propagation with momentum' algorithm.  This is not the place to go through all the mathematics, but for the above sum squared error we can compute and apply one iteration (or '<i>epoch</i>') of the required weight changes <i>DeltaWeightIH</i> and <i>DeltaWeightHO</i> using<P><math><ul>Error = 0.0 ;<BR>for( p = 1 ; p &lt;= NumPattern ; p++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* repeat for all the training patterns */</FONT><BR><ul>for( j = 1 ; j &lt;= NumHidden ; j++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* compute hidden unit activations */</FONT><BR>    <ul>SumH[p][j] = WeightIH[0][j] ;<BR>        for( i = 1 ; i &lt;= NumInput ; i++ ) {<BR>        <ul>SumH[p][j] += Input[p][i] * WeightIH[i][j] ;<BR></ul>        }<BR>        Hidden[p][j] = 1.0/(1.0 + exp(-SumH[p][j])) ;<BR></ul>    }<BR>    for( k = 1 ; k &lt;= NumOutput ; k++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* compute output unit activations and errors */</FONT><BR>    <ul>SumO[p][k] = WeightHO[0][k] ;<BR>        for( j = 1 ; j &lt;= NumHidden ; j++ ) {<BR>        <ul>SumO[p][k] += Hidden[p][j] * WeightHO[j][k] ;<BR></ul>        }<BR>        Output[p][k] = 1.0/(1.0 + exp(-SumO[p][k])) ;<BR>        Error += 0.5 * (Target[p][k] - Output[p][k]) * (Target[p][k] - Output[p][k]) ;<BR>        DeltaO[k] = (Target[p][k] - Output[p][k]) * Output[p][k] * (1.0 - Output[p][k]) ;<BR></ul>    }<BR>    for( j = 1 ; j &lt;= NumHidden ; j++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* 'back-propagate' errors to hidden layer */</FONT><BR>    <ul>SumDOW[j] = 0.0 ;<BR>        for( k = 1 ; k &lt;= NumOutput ; k++ ) {<BR>        <ul>SumDOW[j] += WeightHO[j][k] * DeltaO[k] ;<BR></ul>        }<BR>        DeltaH[j] = SumDOW[j] * Hidden[p][j] * (1.0 - Hidden[p][j]) ;<BR></ul>    }<BR>    for( j = 1 ; j &lt;= NumHidden ; j++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* update weights WeightIH */</FONT><BR>    <ul>DeltaWeightIH[0][j] = eta * DeltaH[j] + alpha * DeltaWeightIH[0][j] ;<BR>        WeightIH[0][j] += DeltaWeightIH[0][j] ;<BR>        for( i = 1 ; i &lt;= NumInput ; i++ ) {        <ul>DeltaWeightIH[i][j] = eta * Input[p][i] * DeltaH[j] + alpha * DeltaWeightIH[i][j];<BR>            WeightIH[i][j] += DeltaWeightIH[i][j] ;<BR></ul>        }<BR></ul>    }<BR>    for( k = 1 ; k &lt;= NumOutput ; k ++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* update weights WeightHO */</FONT><BR>    <ul>DeltaWeightHO[0][k] = eta * DeltaO[k] + alpha * DeltaWeightHO[0][k] ;<BR>        WeightHO[0][k] += DeltaWeightHO[0][k] ;<BR>        for( j = 1 ; j &lt;= NumHidden ; j++ ) {<BR>        <ul>DeltaWeightHO[j][k] = eta * Hidden[p][j] * DeltaO[k] + alpha * DeltaWeightHO[j][k] ;<BR>            WeightHO[j][k] += DeltaWeightHO[j][k] ;<BR></ul>        }<BR></ul>    }<BR></ul>}<BR></ul><math><P>(There is clearly plenty of scope for re-ordering, combining and simplifying the loops here - I will leave that for the reader to do once they have understood what the separate code sections are doing.)  The weight changes <i>DeltaWeightIH</i> and <i>DeltaWeightHO</i> are each made up of two components.  First, the <i>eta</i> component that is the gradient descent contribution, consisting of the 'learning rate'or 'step size' eta multiplied by the gradient.  Second, the <i>alpha</i> component that is a 'momentum' term which effectively keeps a moving average of the gradient descent weight change contributions, and thus smoothes out the overall weight changes.  Fixing good values of the learning parameters <i>eta</i> and <i>alpha</i> is usually a matter of trial and error.  Certainly <i>alpha</i> must be in the range 0 to 1, and a non-zero value does usually speed up learning.  However, setting <i>alpha</i> to zero and having no momentum allows much simplercode. Finding a good value for <i>eta</i> (known as the learning rate or step size)will depend on the problem, and also on the value chosen for <i>alpha</i>.  If it is set too low, the training will be unnecessarily slow.  Having it too large will cause the weight changes to oscillate wildly, and can slow down or even prevent learning altogether.  (I generally start by trying <i>eta</i> = 0.1 and explore the effects of repeatedly doubling or halving it.)  <P>The complete training process will consist of repeating the above weight updates for a number of epochs (using another <i>for</i> loop) until some error crierion is met, for example the <i>Error</i> falls below some chosen small number.  (Note that, with sigmoids on the outputs, the <i>Error</i> can only reach exactly zero if the weights reach infinity!  Note also that sometimes the training can get stuck in a 'local minimum' of the error function and never get anywhere the actual minimum.) So, we need to wrap the last block of code in something like<P><math><ul>for( epoch = 1 ; epoch &lt; LARGENUMBER ; epoch++ ) {<ul><FONT COLOR="#D00000">/* ABOVE CODE FOR ONE ITERATION */</FONT><BR>    if( Error &lt; SMALLNUMBER ) break ;<BR></ul>}<BR></ul><math><P>Naturally, one must set some initial network weights to start the learning process.  Starting all the weights at zero is generally not a good idea, as that is often a local minimum of the error function.  It is normal to initialize all the weights with small random values.  If <i>rando()</i> is your favourite random number generator function that returns a flat distribution of random numbers in the range 0 to 1, and <i>smallwt</i> is the maximum absolute size of your initial weights, then an appropriate section of weight initialization code would be<P><math><ul>for( j = 1 ; j &lt;= NumHidden ; j++ ) {    <FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* initialize WeightIH and DeltaWeightIH */</FONT><BR>    <ul>for( i = 0 ; i &lt;= NumInput ; i++ ) { <BR>        <ul>DeltaWeightIH[i][j] = 0.0 ;<BR>             WeightIH[i][j] = 2.0 * ( rando() - 0.5 ) * smallwt ;<BR></ul>         }<BR></ul>     }<BR>     for( k = 1 ; k &lt;= NumOutput ; k ++ ) {    <FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* initialize WeightHO and DeltaWeightHO */</FONT><BR>     <ul>for( j = 0 ; j &lt;= NumHidden ; j++ ) {<BR>         <ul>DeltaWeightHO[j][k] = 0.0 ;<BR>                           WeightHO[j][k] = 2.0 * ( rando() - 0.5 ) * smallwt ;<BR></ul>         }<BR></ul>     }<BR></ul></math><P>Note, that it is a good idea to set all the initial <i>DeltaWeights</i> to zero at the same time.  The best value for <i>smallwt</i> will depend on the problem - but they should never be so large that the sigmoids saturate before thetraining begins (i.e. start too close to zero or one).<P>If the training patterns are presented in the same systematic order during each epoch, it is possible for weight oscillations to occur.  It is therefore generally a good idea to use a new random order for the training patterns for each epoch.  If we put the <i>NumPattern</i> training pattern indices <i>p</i> in random order into an array <i>ranpat[]</i>, then it is simply a matter of replacing our training pattern loop<P><math>    <ul>for( p = 1 ; p &lt;= NumPattern ; p++ ) {<BR></ul></math><P>with<P><math>    <ul>for( np = 1 ; np &lt;= NumPattern ; np++ ) {<BR>        <ul>p = ranpat[np] ;<BR></ul></ul></math><P>Generating the random array <i>ranpat[]</i> is not quite so simple, but the following code will do the job<P><math>    <ul>for( p = 1 ; p &lt;= NumPattern ; p++ ) {<FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* set up ordered array */</FONT><BR>	<ul>ranpat[p] = p ;<BR></ul>        }<BR>	for( p = 1 ; p &lt;= NumPattern ; p++) {   <FONT COLOR="#D00000">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* swap random elements into each position */</FONT><BR>	<ul>np = p + rando() * ( NumPattern + 1 - p ) ;<BR>	    op = ranpat[p] ; ranpat[p] = ranpat[np] ; ranpat[np] = op ;<BR></ul>	}<BR></ul></math><P>We now have enough code to put together a working neural network program.  I have cut and pasted the above code into the file <A HREF="nn.c">nn.c</A> (which your browser should allow you to save into your own file space).  I have added the standard #includes, declared all the variables, hard coded the standard XOR training data and values for <i>eta</i>, <i>alpha</i> and <i>smallwt</i>, #defined an overly-simple <i>rando()</i>, added some print statements to show what the network is doing, and wrapped the whole lot in a <i>main(){ }</i>.  The file should compile and run in the normal way (e.g., using the UNIX commands 'cc nn.c -O -lm -o nn' and 'nn').<P>I've left plenty for the reader to do to convert this into a useful program, for example:<ul><li>Reading in training and testing data from file</li><li>Allowing the parameters (<i>eta</i>, <i>alpha</i>, <i>smallwt</i>, <i>NumHidden</i>, etc.) to be varied during runtime</li><li>Having appropriate array sizes determined from the training data and allocating them memory during runtime</li><li>Saving the network weights to file, and reading them back in again</li><li>Plotting of errors, output activations, etc. during training</li></ul><P>There are also numerous network variations that could usefully be implemented, for example:<ul><li>Batch learning, rather than on-line learning</li><li>Separate training, validation and testing data sets</li><li>More sophisticated techniques for stopping the training<li>Weight decay or other regularization approaches</li><li>Different architectures, e.g. more hidden layers, direct input-to-output connections, partial connectivity, etc.</li><li>Regression problems require linear output functions, rather than sigmoids</li><math><ul>Output[p][k] = SumO[p][k] ;<BR></ul><ul>DeltaO[k] = Target[p][k] - Output[p][k] ;<BR></ul></math><li>Classification problems should use the Cross-Entropy error function, rather than Sum Squared Error</li><math><ul>Error -= ( Target[p][k] * log( Output[p][k] ) + ( 1.0 - Target[p][k] ) * log( 1.0 - Output[p][k] ) ) ;<BR></ul><ul>DeltaO[k] = Target[p][k] - Output[p][k] ;<BR></ul></math><li>Muliple-class classification problems should really use the Softmax activation function</li></ul>But from here on, you're on your own.  I hope you found this page useful...<P></FONT><HR><FONT SIZE=2 FACE="Arial,Helvetica,Univers,Zurich BT,sans-serif"><CENTER>This page is maintained by<A HREF="../index.html">John Bullinaria</a>.Last updated on 14 October 2009.</CENTER></FONT></BODY></HTML>