<HTML>
<HEAD>
<TITLE>Introduction to Neural Networks</TITLE>
</HEAD>
<BODY>

<BODY BGCOLOR="#FFFFFF">
<FONT COLOR="#D00000">
<H1 ALIGN=CENTER>(2nd Year UG / MSc in Computer Science)</H1>
<H1 ALIGN=CENTER>Introduction to Neural Networks - Course Material and Useful Links</H1>
<H1 ALIGN=CENTER><a href="index.html">Dr John A. Bullinaria</a></H1>
</FONT>
<P>
<P ALIGN="CENTER"><A HREF="mailto:j.a.bullinaria@cs.bham.ac.uk">j.a.bullinaria@cs.bham.ac.uk</A></P>

<P><HR>

<P><H3 ALIGN=CENTER>I no longer teach this module, but this web-page is now sufficiently 
widely used that I will leave it in place. It contains all the overheads, handouts, and exercise 
sheets used in the lectures, details about the continuous assessment and examination, and so on, 
for the academic year 2004/5. 
You may be more interested in 
<a href="inc.html">the module I currently teach in this area</a>.</H3>
<P><HR>

<h3><font COLOR="#D00000">Lecture Timetable and Handouts</font></h3>

<P>Here's an outline of the module structure and lecture timetable.  All the module handouts 
were made available here as pdf files shortly after the paper versions were distributed in 
the lectures.  

<P><TABLE BORDER="1" BGCOLOR="#FFFFCC" WIDTH=100%>
<TR>
        <TH WIDTH="6%" VALIGN="MIDDLE" BGCOLOR="#99CCFF">
        Week</TH>
        <TH WIDTH="47%" VALIGN="MIDDLE" BGCOLOR="#99CCFF">
        Session 1 <BR><FONT COLOR="RED">Wednesdays 12:00-13:00</FONT>
        </TH><TH WIDTH="47%" VALIGN="MIDDLE" BGCOLOR="#99CCFF">
        Session 2 <BR><FONT COLOR="RED">Thursdays 10:00-11:00</FONT>
</TH></TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">1</TD>
<TD>Introduction to Neural Networks and their History. 
<a href="INN/l1.pdf">[pdf]</a></TD>
<TD>Biological Neurons and Neural Networks.  Artificial Neurons. 
<a href="INN/l2.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">2</TD>
<TD>Networks of Artificial Neurons.  Single Layer Perceptrons.
<a href="INN/l3.pdf">[pdf]</a></TD>
<TD>Learning and Generalization in Single Layer Perceptrons.
<a href="INN/l4.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">3</TD>
<TD>Hebbian Learning.  Gradient Descent Learning.
<a href="INN/l5.pdf">[pdf]</a></TD>
<TD>The Generalized Delta Rule.  Practical Considerations.
<a href="INN/l6.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">4</TD>
<TD>Learning in Multi-Layer Perceptrons.  Back-Propagation.
<a href="INN/l7.pdf">[pdf]</a></TD>
<TD>Learning with Momentum.  Conjugate Gradient Learning.
<a href="INN/l8.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">5</TD>
<TD>Bias and Variance. Under-Fitting and Over-Fitting.
<a href="INN/l9.pdf">[pdf]</a></TD>
<TD>Improving Generalization.
<a href="INN/l10.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">6</TD>
<TD>Applications of Multi-Layer Perceptrons.
<a href="INN/l11.pdf">[pdf]</a></TD>
<TD><FONT COLOR=GREEN>Exercise Session 1</FONT>
</TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">7</TD>
<TD>Radial Basis Function Networks: Introduction.
<a href="INN/l12.pdf">[pdf]</a></TD>
<TD>Radial Basis Function Networks: Algorithms.
<a href="INN/l13.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">8</TD>
<TD>Radial Basis Function Networks: Applications.
<a href="INN/l14.pdf">[pdf]</a></TD>
<TD>Committee Machines.
<a href="INN/l15.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">9</TD>
<TD><FONT COLOR=GREEN>Exercise Session 2</FONT>
</TD>
<TD>Self Organizing Maps: Fundamentals.
<a href="INN/l16.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">10</TD>
<TD>Self Organizing Maps: Algorithms and Applications.
<a href="INN/l17.pdf">[pdf]</a></TD>
<TD>Learning Vector Quantization (LVQ). 
<a href="INN/l18.pdf">[pdf]</a></TD>
</TR>

<TR>
<TD ALIGN="CENTER" WIDTH="6%">11</TD>
<TD>Overview of More Advanced Topics.
<a href="INN/l19.pdf">[pdf]</a></TD>
<TD><FONT COLOR=GREEN>Exercise Session 3</FONT>
</TD></TR>

</TABLE></P>


<TABLE BORDER="1" BGCOLOR="#FFFFCC" WIDTH=100%>
<TR>
<TD ALIGN="CENTER" WIDTH="6%">12</TD>
<TD ALIGN="CENTER" WIDTH="94%"><FONT COLOR=GREEN>Two Revision Lectures Covering the Whole 
Module</FONT> <a href="INN/lR.pdf">[pdf]</a></TD>
</TR>
</TABLE></P>


<h3><font COLOR="#D00000">Aims, Learning Outcomes and Assessment</font></h3>

<P>For formal details about the aims, learning outcomes and assessment you should look at the official 
<a href="http://www.cs.bham.ac.uk/resources/modules/2004/mds/md-02360.html">Module Description Page</a>
and <a href="http://www.cs.bham.ac.uk/resources/modules/2004/02360.html">Syllabus Page</a>.
	
<P>There are two components to the assessment of this module: A two hour examination (70%) and
a continuous assessment by mini-project report (30%).  (NB The module description says "resit by written 
examination only with the continuous assessment mark carried forward", so resit students DO NOT
do this year's continuous assessment mini-project!)

<P>A series of exercise sheets, largely based on recent past examination questions, will give an 
idea of the standard and type of questions you can expect in this year's examination.  These
will be distributed when the associated material has been covered in the lectures.  They do not 
contribute to the assessment for the module.  The Exercise Sessions will be used to talk through
appropriate answers to the questions on the Exercise Sheets.
They have now all been distributed: 
<a href="INN/ex1.pdf">Exercise Sheet 1</a>,
<a href="INN/ex2.pdf">Exercise Sheet 2</a>,
<a href="INN/ex3.pdf">Exercise Sheet 3</a>,
<a href="INN/ex4.pdf">Exercise Sheet 4</a> and
<a href="INN/ex5.pdf">Exercise Sheet 5</a>.

<P>I have also produced an <a href="INN/equations.pdf">Equation Sheet</a>
which contains the main equations that you should be familiar with from the module.  

<h3><font COLOR="#D00000">The Continuous Assessment Mini-Project</font></h3>

<P>The <a href="INN/cann.pdf">Continuous Assessment Assignment</a> was
distributed and discussed in Exercise Session 1.

<P>The objective of this exercise is for you to gain practical experience in setting up, training and optimising
a neural network designed to recover the underlying function from a set of noisy training data  

<P>The data sets for the project are generated individually for each student:  Download the data generation 
program called <a href="INN/datagen">datagen</a> from here (using the right
mouse button usually).  It is compiled to run on the School's Linux PCs.  Enter 'chmod 700 datagen' on the 
linux prompt to make it an executable, and then run it to generate the data.  

<P>You may use any software you wish to run the specified neural network simulations, but we have 
installed the <I>javaNNS</I> simulator on the School's system for use on the Linux PCs.  
If you have not used this software before, you may want to begin by taking a look at my 
<A HREF="INN/javaNNS/javaNNSstart.html">Getting Started with javaNNS page</a>,
and then at my <A HREF="INN/javaNNS/javaNNSguide.html">Quick Guide to javaNNS</a>.
Beyond that, there is a fairly comprehensive on-line help system to guide you.

<P>This package is also good for exploring the other aspects of neural networks that are discussed
in this module. 

<P>For those of you who might be interested in programming your own neural networks, rather than using <I>javaNNS</I>,
I've written a web page giving a <A HREF="INN/nn.html">Step by Step Guide
to Implementing a Simple Neural Network in C</A> which will get you started.  It should be fairly
straightforward to see how to use it with related programming languages such as C++ and Java. 


<h3><font COLOR="#D00000">Recommended Books and Links</font></h3>

<P>The Recommended Books for this module are:
<P><TABLE BORDER="1" BGCOLOR="#FFFFCC" WIDTH=100%>
<tr>
<th bgcolor="#99CCFF" valign="TOP" width="35%">Title</th>
<th bgcolor="#99CCFF" valign="TOP" width="20%">Author(s)</th>
<th bgcolor="#99CCFF" valign="TOP" width="20%">Publisher, Date</th>
<th bgcolor="#99CCFF" valign="TOP" width="25%">Comments</th>
</tr>
<tr>
<td valign="TOP" width="35%">An Introduction to Neural Networks</td>
<td valign="TOP" width="20%">Kevin Gurney</td>
<td valign="TOP" width="20%">Routledge, 1997</td>
<td valign="TOP" width="25%">Non-mathematical introduction.</td>
</tr>
<tr>
<td valign="TOP" width="35%">Neural Networks: A Comprehensive Foundation</td>
<td valign="TOP" width="20%">Simon Haykin</td>
<td valign="TOP" width="20%">Prentice Hall, 1999</td>
<td valign="TOP" width="25%">Very comprehensive and up-to-date, but heavy in maths.</td>
</tr>
<tr>
<td valign="TOP" width="35%">Neural Networks for Pattern Recognition</td>
<td valign="TOP" width="20%">Christopher Bishop</td>
<td valign="TOP" width="20%">Clarendon Press, Oxford, 1995</td>
<td valign="TOP" width="25%">This is the book I always use.</td>
</tr>
<tr>
<td valign="TOP" width="35%">Fundamentals of Neural Networks</td>
<td valign="TOP" width="20%">Laurene Fausett</td>
<td valign="TOP" width="20%">Prentice Hall, 1994</td>
<td valign="TOP" width="25%">Good intermediate text.</td>
</tr>
<tr>
<td valign="TOP" width="35%">The Essence of Neural Networks</td>
<td valign="TOP" width="20%">Robert Callan</td>
<td valign="TOP" width="20%">Prentice Hall Europe, 1999</td>
<td valign="TOP" width="25%">Worth reading.</td>
</tr>
<tr>
<td valign="TOP" width="35%">Introduction to Neural Networks</td>
<td valign="TOP" width="20%">R. Beale &amp; T. Jackson</td>
<td valign="TOP" width="20%">IOP Publishing, 1990</td>
<td valign="TOP" width="25%">Introductory text.</td>
</tr>
<tr>
<td valign="TOP" width="35%">An Introduction to the Theory of Neural Computation</td>
<td valign="TOP" width="20%">J. Hertz, A. Krogh &amp; R.G. Palmer</td>
<td valign="TOP" width="20%">Addison Wesley, 1991</td>
<td valign="TOP" width="25%">Good all round book.  Slightly mathematical.</td>
</tr>
<tr>
<td valign="TOP" width="35%">Principles of Neurocomputing for Science and Engineering</td>
<td valign="TOP" width="20%">F. M. Ham &amp; I. Kostanic</td>
<td valign="TOP" width="20%">McGraw Hill, 2001</td>
<td valign="TOP" width="25%">Good advanced book, but rather mathematical.</td>
</tr>
</table>

<P>If you can only afford to buy one book for this module, I would recommend getting the one by Haykin 
if you have a resonably mathematical background, or the one by Gurney if you don't.

<P>If you want to find online information about Neural Networks, probably the best places to start are:
<a href="ftp://ftp.sas.com/pub/neural/FAQ.html">The Neural Networks FAQ</a> web-site, and the
<a href="http://lcn.epfl.ch/tutorial/english/weblinks.html">Neural Network Resources</a> web-site,
both of which contain a large range of information and links about all aspects of neural networks.

<BR>
<P><HR><FONT SIZE=2 FACE="Arial,Helvetica,Univers,Zurich BT,sans-serif">
<CENTER>This page is maintained by
<a href="">John Bullinaria</a>.
Last updated on 15 June 2005.
</CENTER></FONT>

</HTML>
